{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d8179-6f23-4a36-86a6-ce0647fe7218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports & load precomputed CSVs\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "# expected files (already precomputed and committed)\n",
    "CHAP_LEMMAS_CSV = DATA_DIR / \"chap_lemmas.csv\"\n",
    "SENTIMENT_CSV = DATA_DIR / \"sentiment_by_chapter.csv\"\n",
    "\n",
    "# load them defensively\n",
    "if not CHAP_LEMMAS_CSV.exists():\n",
    "    raise FileNotFoundError(f\"{CHAP_LEMMAS_CSV} not found. Commit this file to the repo before launching Binder.\")\n",
    "chap_lemmas_df = pd.read_csv(CHAP_LEMMAS_CSV, encoding=\"utf-8\")\n",
    "chap_lemmas_df['chapter'] = pd.to_numeric(chap_lemmas_df['chapter'], errors='coerce').fillna(0).astype(int)\n",
    "chap_lemmas_df['lemmas_str'] = chap_lemmas_df['lemmas_str'].fillna(\"\").astype(str)\n",
    "chap_lemmas_df['word_count'] = pd.to_numeric(chap_lemmas_df.get('word_count', 0), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "if SENTIMENT_CSV.exists():\n",
    "    sentiment_df = pd.read_csv(SENTIMENT_CSV)\n",
    "else:\n",
    "    sentiment_df = None\n",
    "\n",
    "display(HTML(\"<h2>Dracula â€” interactive term frequency (lemmatized)</h2>\"))\n",
    "display(HTML(\"<p>Type a single lemmatized word (e.g., <em>vampire</em>) and click Plot. Use Normalize to show per 1,000 words.</p>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca333e0-3481-4d84-92b3-0b7785c7c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers: build per-chapter counters from lemmas_str (fast)\n",
    "from collections import Counter\n",
    "_lemma_counters = []\n",
    "for s in chap_lemmas_df['lemmas_str'].tolist():\n",
    "    if not s:\n",
    "        _lemma_counters.append(Counter())\n",
    "    else:\n",
    "        # lemmas_str expected to be space-joined lemmas\n",
    "        _lemma_counters.append(Counter(s.split()))\n",
    "\n",
    "def lemmatize_query_simple(q):\n",
    "    # here we assume user types the lemma already; we do a simple normalization\n",
    "    q = (q or \"\").strip().lower()\n",
    "    # restrict to single word alpha\n",
    "    m = re.findall(r'[a-z]+', q)\n",
    "    return m[0] if m else None\n",
    "\n",
    "def counts_for_lemma(lemma):\n",
    "    if not lemma:\n",
    "        return [0]*len(_lemma_counters)\n",
    "    return [c.get(lemma, 0) for c in _lemma_counters]\n",
    "\n",
    "def make_plot_df_for_lemma(lemma, normalize=False):\n",
    "    counts = counts_for_lemma(lemma)\n",
    "    df = pd.DataFrame({\n",
    "        \"chapter\": chap_lemmas_df['chapter'].astype(int),\n",
    "        \"count\": counts,\n",
    "        \"word_count\": chap_lemmas_df['word_count'].astype(int)\n",
    "    }).sort_values('chapter').reset_index(drop=True)\n",
    "    df = df[df['chapter'] > 0]   # drop preface if present\n",
    "    if normalize:\n",
    "        df['norm_per_1k'] = df['count'] / (df['word_count'].replace({0:1}) / 1000.0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95aaf20-4113-4a71-a4d7-e94e4ab3aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI: text input, normalize checkbox, plot button, output\n",
    "term_input = widgets.Text(value=\"\", placeholder=\"Type a lemma, e.g. vampire\", description=\"Term:\", layout=widgets.Layout(width=\"60%\"))\n",
    "normalize_chk = widgets.Checkbox(value=False, description=\"Normalize (per 1k words)\")\n",
    "plot_btn = widgets.Button(description=\"Plot\", button_style=\"primary\")\n",
    "out = widgets.Output(layout=widgets.Layout(width=\"100%\"))\n",
    "\n",
    "def render_query(q, normalize=False):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        lemma = lemmatize_query_simple(q)\n",
    "        if not lemma:\n",
    "            print(\"Please enter a single word lemma (a-z).\")\n",
    "            return\n",
    "        df = make_plot_df_for_lemma(lemma, normalize=normalize)\n",
    "        if df.empty or df['count'].sum() == 0:\n",
    "            print(f\"No occurrences of '{lemma}' found.\")\n",
    "            return\n",
    "        ycol = 'norm_per_1k' if normalize else 'count'\n",
    "        ylabel = \"Occurrences per 1,000 words\" if normalize else \"Raw occurrences\"\n",
    "        fig = px.line(df, x='chapter', y=ycol, markers=True,\n",
    "                      title=f\"Frequency of '{lemma}' by chapter\",\n",
    "                      labels={'chapter': 'Chapter', ycol: ylabel})\n",
    "        fig.update_layout(height=420, margin=dict(l=40, r=20, t=60, b=40), xaxis=dict(dtick=1))\n",
    "        fig.show()\n",
    "\n",
    "def on_click(b):\n",
    "    render_query(term_input.value, normalize_chk.value)\n",
    "\n",
    "plot_btn.on_click(on_click)\n",
    "# allow Enter in textbox where supported\n",
    "try:\n",
    "    term_input.on_submit(lambda widget: render_query(widget.value, normalize_chk.value))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "display(widgets.HBox([term_input, plot_btn, normalize_chk]))\n",
    "display(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iubl-dracula .venv)",
   "language": "python",
   "name": "iubl-dracula-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
